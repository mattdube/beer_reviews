---
title: "Beer Ratings Analysis"
output: html_notebook
author: "Matt Dube"
date: "12/7/2018"
editor_options: 
  chunk_output_type: inline
---

load libraries
```{r message=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(here)
library(corrplot)
library(Hmisc)

```
load data
```{r, message=FALSE}
beer <- read_csv(here("00_Data/raw/","beer_reviews.csv"))

```

Look at structure of data.  The below are a few of the things I look at everytime I load a new dataset.  

* structure

* feature data types

* summary statistics

* missing values
```{r}
dim(beer)
```
 The beer data set has 1,586,614 observations., and 13 features.
```{r}
glimpse(beer)
```

The glimpse function shows the datatype of all features, and also several examples of each one (number of examples depends on what fits on the screen).

```{r}
summary(beer)
```
The summary function provides descriptive statistics (IQR, min, mean, max) for numeric features.  It looks like only beer_abv has missing values.  I'll check again with less output to make sure.

```{r}
sapply(beer, function(x) sum(is.na(x)))
```
sapply applies the function 'sum(is.na(x)) across all columns in the dataset.  Confirmed, only beer_abv has missing values.  

```{r}
67785 / nrow(beer) * 100
```
4.27% of reviews have missing data.  

#### Question 1: Which brewery produces the strongest beers by ABV%?

There's a 3-step process to answer this question:

* get distinct list of beers using the distinct function. 

* group by brewery

* find the average ABV% for all the beers by brewery. Group_by works with summarise to first put bin our data into groups, in this case by the variable 'brewery_name', then summarise applies an aggregate function to the data **by group**.  For this question the function 'mean' is applied to beer_abv, and it's aggregated by brewery_name.

'arrange' allows the results to be sorted in **descending** order.

```{r}
beer %>%
    distinct(brewery_name, brewery_id, beer_name, beer_beerid, beer_abv) %>% 
    group_by(brewery_name) %>%
    summarise(mean_abv = mean(beer_abv)) %>% 
    arrange(desc(mean_abv)) %>%
    head(5)
```

The brewery that produces the strongest beers by ABV% is **SchorschbrÃ¤u** with a mean abv of **24.69**.


#### Question 2: If you had to pick 3 beers to recommend using only this data, which would you pick?

First set is to add a review_count column, which is the total number of times a unique beer was reviewed.
```{r}
beer_processed <- 
    beer %>% 
    group_by(beer_name, beer_beerid) %>%
    mutate(review_count = n())
```

Next, I'm choosing an arbitrary number of minimum reviews to base my selection on.  In this case, I think that a minimum of 20 reviews for a beer is needed before it can be considered for the overall recommendation.

The steps to choose the 3 beers are:

1. Filter on beers with at least 20 reviews.

2. Group_By Beer Name, Beer ID, and Brewery.

3. Find the mean overall rating (review_overall) for those beers.

4. Arrange the results in descending order by mean_over_all rating.

```{r recommendation}
beer_processed %>%
  filter(review_count >= 20) %>%
  group_by(beer_name, beer_beerid, brewery_name) %>%
  summarise(mean_overall_rating = mean(review_overall, na.rm=TRUE), n()) %>%
  select(mean_overall_rating, beer_name, everything()) %>%
  arrange(desc(mean_overall_rating, n)) %>%
  head(3)
```


The 3 beers I would recommend are 

* **Rare D.O.S.** from Peg's Cantina & Brewpub / Cycle Brewing

* **Dirty Horse** from De Struise Brouwers

* **Southampton Berliner Weisse** from Southampton Publick House

**Note** - this answer will change based on the filter of number of beer reviews.  


#### Question 3: Which of the factors (aroma, taste, appearance, palate) are most important in determining the overall quality of a beer?

My initial thought to answer question 3 was to build a model, then look at variable importance.  But while that would give an answer, a much easier way to answer this is to look at the correlation of the 4 features with the overall rating, which I interpret to be the overall quality of the beer.  

First step, check the distribution of aroma, taste, appearance, and palate.

A fuction to plot a list of variables:
```{r}
plotHistograms <- function(varList, inputData, numCols=2) {
    gather(data=inputData, varList, key = "var", value = "value") %>%
        ggplot(aes(x=value)) +
        geom_histogram(fill="#2b8cbe") +
        facet_wrap(~ var, scales = "free", ncol = numCols) +
        theme(legend.position = "none")
}

```
Call the function with our list:
```{r}
num_list <- c("review_overall", "review_aroma", "review_taste", "review_appearance", "review_palate")
plotHistograms(num_list, beer)
```
All five variables distributions are basically the same, and close to normal.  We can use Pearson's correlation to examine the strength of their relationships.  We can further check the relationship using Spearman's Rank Correlation, which doesn't make assumptions about the distribution.

```{r}
beer_corr_full_pe <- 
    beer %>%
    dplyr::select(review_overall, review_aroma, review_taste, review_appearance, review_palate) %>%
    cor(method = "pearson")

beer_corr_full_sp <- 
    beer %>%
    dplyr::select(review_overall, review_aroma, review_taste, review_appearance, review_palate) %>%
    cor(method = "spearman")
```

```{r}
corrplot(beer_corr_full_pe, method="number", type = "upper",tl.cex = 0.75,
         mar=c(0,0,2,0), title = "Pearson correlation") 
```

```{r}
corrplot(beer_corr_full_sp, method="number", type = "upper",tl.cex = 0.75,
         mar=c(0,0,2,0), title = "Spearman rank-order correlation") 
```

Both Pearson and Spearman identify **review_taste** as the most important variable in determining the **review_overall** score.  


#### Question 4: Generate 10,000 random numbers (i.e. sample) from a binomial distribution with p = 0.5 and N=20. Do not use any libraries or packages except basic math library functions and a random number generator (such as runif in R or random.random in python).

Plot the histogram of the data.

The *rbinom* base R function can be used with the base R *hist* to answer this:

```{r}
set.seed(5432)
hist(rbinom(10000, 20, 0.5))
```

Here's 10,000 random numbers from a binomial distribution using only runif. 

The process used:

* create random number using runif, with 20 samples, between 0 and 1.

* using the random number above, create  bernoulli distributed variables using 0.5 probability.
This will result in a logical TRUE/FALSE, so 'as.numeric' needs to be used.

* the bernoulli distribution is summed.

* this is 1 sample - we need 10,000.

** create an empty vector to store results

** use a for loop to run the above steps 10,000 times to come up with the full sample.

Here is an example of creating the random 20 samples, creating a bernoulli distribution, and summing that distribution.

I reviewed binomial and bernoulli distributions here:

https://math.stackexchange.com/questions/838107/what-is-the-difference-and-relationship-between-the-binomial-and-bernoulli-distr

```{r}
set.seed(5432)

# random numbers
random_num <- runif(20, 0, 1)
# bernoulli distribution with 0.5 probability
bern_dist <- as.numeric(random_num < 0.5)

```
```{r}
print(random_num)
print(bern_dist)
```

Now we can do the same thing, but for 10,000 numbers.
The random_binom function defined below takes 3 parameters:

* x - the number of random numbers.

* n - the number of samples.

* p - the probability.

```{r}
set.seed(5432)

random_binom <- function(x, n, p){
  binom_dist <- c()
  for(i in 1:x){
    samp <- runif(n, 0, 1) # random sample fo 20 numbers between 0 and 1
    bern <- as.numeric(samp < p) # create bernoulli distribution with p = 0.5
    binom_dist[i] <- sum(bern) # sum each bernoulli distribution and add to the vector
  }
  return(binom_dist)
}
```
Use the hist() function to plot the binomial distribution of 10,000 numbers from a binomial distribution with p = 0.5 and N = 20.
```{r}
hist(random_binom(10000, 20, 0.5))
```
